{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.12\n",
    "import google.datalab.bigquery as bq\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "from pandas.io import gbq\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow import keras\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"#standardSQL\n",
    "CREATE TEMP FUNCTION\n",
    "  customDimensionByIndex(indx INT64,\n",
    "    arr ARRAY<STRUCT<index INT64,\n",
    "    value STRING>>) AS ( (\n",
    "    SELECT\n",
    "      x.value\n",
    "    FROM\n",
    "      UNNEST(arr) x\n",
    "    WHERE\n",
    "      indx=x.index) );\n",
    "SELECT\n",
    "  fullVisitorId,\n",
    "  visitId,\n",
    "  EXTRACT(HOUR from TIMESTAMP_SECONDS(visitStartTime)) AS VisitingHour,\n",
    "  EXTRACT(DAYOFWEEK from TIMESTAMP_SECONDS(visitStartTime)) AS VisitingDayOfWeek,\n",
    "  trafficSource.source, \n",
    "  device.browser,\n",
    "  device.operatingSystem,\n",
    "  device.LANGUAGE,\n",
    "  device.deviceCategory,\n",
    "  \n",
    " ---session scope custom dimension---\n",
    "  customDimensionByIndex(3,\n",
    "    t.customDimensions) AS contentCategory, \n",
    "  ---User scope custom dimension---\n",
    "  EXTRACT(YEAR FROM CURRENT_DATE())- CAST(SUBSTR(customDimensionByIndex(6,t.customDimensions),1,4) AS NUMERIC) AS userAge\n",
    "\n",
    "FROM\n",
    "  `tencent-ga-bigquery-217708.18845258.ga_sessions_*`t\n",
    "WHERE\n",
    "  _TABLE_SUFFIX BETWEEN '20181001' AND '20181201' \n",
    "    --filter out rows that gender is null\n",
    "   AND customDimensionByIndex(6,t.customDimensions) IS NOT NULL\n",
    "   AND(\n",
    "    --filter for correct syntax of birthdays \n",
    "    REGEXP_CONTAINS(customDimensionByIndex(6,t.customDimensions),r'^\\\\d{8}$')\n",
    "    OR REGEXP_CONTAINS(customDimensionByIndex(6,t.customDimensions),r'^\\\\d{4}-\\\\d{2}-\\\\d{2}$')\n",
    "  ) \n",
    "  \n",
    "limit 1000000\n",
    "\"\"\"\n",
    "\n",
    "data_original = gbq.read_gbq(query,project_id = \"tencent-ga-bigquery-217708\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_original.copy()\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.hist(data.userAge.astype('int'), bins = range(5,75,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with null values\n",
    "data.dropna(axis=0, inplace=True)\n",
    "# remove rows where userAge=5 or userAge>=70\n",
    "data = data[(data.userAge>=5) & (data.userAge<70)]\n",
    "\n",
    "data = data.drop(['visitId','VisitingHour','VisitingDayOfWeek'],axis=1)\n",
    "\n",
    "# prepare column browser, change browers that are not specified below to 'other'\n",
    "data.loc[(data.browser != 'Chrome') &\n",
    "         (data.browser != 'Safari') &\n",
    "         (data.browser != 'Firefox') &\n",
    "         (data.browser != 'Samsung Internet') &\n",
    "         (data.browser != 'Android Webview') &\n",
    "         (data.browser != 'Edge') &\n",
    "         (data.browser !='Internet Explorer'),'browser'] = 'other'\n",
    "\n",
    "# prepare column language\n",
    "data.rename(columns = {'LANGUAGE':'language'}, inplace=True)\n",
    "data.loc[data.language.str.contains('en'),'language'] = 'en'  #data has inconsistent values e.g. 'en','en-en','en-bg'\n",
    "data.loc[data.language.str.contains('th'),'language'] = 'th'\n",
    "data.language.str.contains('en|th')\n",
    "data.loc[(data.language!='th') & \n",
    "         (data.language!='en'),'language'] = 'other'\n",
    "\n",
    "# prepare column operatingSystem\n",
    "data.loc[(data.operatingSystem != 'Windows') &\n",
    "         (data.operatingSystem != 'Android') &\n",
    "         (data.operatingSystem != 'Macintosh') &\n",
    "         (data.operatingSystem !='iOS'),'operatingSystem'] = 'other'\n",
    "\n",
    "# prepare column source \n",
    "data.loc[data.source.str.contains('facebook'),'source'] = 'facebook' #data has inconsistent value such as 'facebook','facebook.com'\n",
    "data.loc[data.source.str.contains('google'),'source'] = 'google'\n",
    "data.loc[data.source.str.contains('sanook'),'source'] = 'sanook'\n",
    "data.loc[data.source.str.contains('direct'),'source'] = 'direct'\n",
    "data.loc[(data.source != 'facebook') &\n",
    "         (data.source != 'google') &\n",
    "         (data.source != 'sanook') &\n",
    "         (data.source !='direct'),'source'] = 'other'\n",
    "\n",
    "# remove rows where contentCategory contains non-english characters\n",
    "data = data[data.contentCategory.str.contains('^[A-Za-z]+$', regex=True)]\n",
    "data.loc[:,'contentCategory'] = data.contentCategory.str.lower()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pivot_table(columns):\n",
    "    result =None\n",
    "    for column in columns:\n",
    "        pivot = data.loc[:,['fullVisitorId',column]]\n",
    "        pivot = pivot.pivot_table(index='fullVisitorId',columns=column,aggfunc= any)\n",
    "        pivot.columns = ['_'.join((column,i)) for i  in pivot.columns]\n",
    "        if result is None:\n",
    "          result = pivot\n",
    "        else:\n",
    "          result = result.join(pivot)\n",
    "        \n",
    "    result = result.replace({\n",
    "      True:1,\n",
    "      None:0\n",
    "    })\n",
    "    return result\n",
    "\n",
    "age = data.loc[:,['fullVisitorId','userAge']].drop_duplicates().set_index('fullVisitorId')    \n",
    "data = make_pivot_table(data.columns[1:-1])\n",
    "data = data.join(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with less than 0.1% of 1s  \n",
    "#data = data[data.columns[data.sum()>data.shape[0]*0.001]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## without bins  #################\n",
    "\n",
    "train_dataset = data.sample(frac=0.8,random_state=0).astype('float64')   #############\n",
    "test_dataset = data.drop(train_dataset.index).astype('float64')\n",
    "\n",
    "train_labels = train_dataset['userAge']\n",
    "train_dataset = train_dataset.drop('userAge',axis = 1)\n",
    "test_labels = test_dataset['userAge']\n",
    "test_dataset = test_dataset.drop('userAge',axis = 1)\n",
    "\n",
    "#covnert dataframe to ndarrays for tensorflow input \n",
    "train_dataset = train_dataset.values\n",
    "train_labels = train_labels.values\n",
    "test_dataset = test_dataset.values\n",
    "test_labels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288096 samples, validate on 72024 samples\n",
      "Epoch 1/20\n",
      "288096/288096 [==============================] - 3s 10us/step - loss: 835.3520 - mean_absolute_error: 25.1352 - val_loss: 182.1370 - val_mean_absolute_error: 10.5977\n",
      "Epoch 2/20\n",
      "288096/288096 [==============================] - 2s 7us/step - loss: 340.7842 - mean_absolute_error: 14.7906 - val_loss: 163.6230 - val_mean_absolute_error: 10.0956\n",
      "Epoch 3/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 317.4577 - mean_absolute_error: 14.2506 - val_loss: 157.0420 - val_mean_absolute_error: 9.9113\n",
      "Epoch 4/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 302.2951 - mean_absolute_error: 13.8852 - val_loss: 154.3927 - val_mean_absolute_error: 9.8377\n",
      "Epoch 5/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 287.3378 - mean_absolute_error: 13.5348 - val_loss: 157.0582 - val_mean_absolute_error: 9.9006\n",
      "Epoch 6/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 267.6043 - mean_absolute_error: 13.0415 - val_loss: 143.3733 - val_mean_absolute_error: 9.5621\n",
      "Epoch 7/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 252.9756 - mean_absolute_error: 12.6875 - val_loss: 142.9724 - val_mean_absolute_error: 9.5524\n",
      "Epoch 8/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 240.8158 - mean_absolute_error: 12.3808 - val_loss: 146.3994 - val_mean_absolute_error: 9.6375\n",
      "Epoch 9/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 233.1708 - mean_absolute_error: 12.1899 - val_loss: 139.2888 - val_mean_absolute_error: 9.4769\n",
      "Epoch 10/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 228.3077 - mean_absolute_error: 12.0863 - val_loss: 137.5684 - val_mean_absolute_error: 9.4433\n",
      "Epoch 11/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 227.0203 - mean_absolute_error: 12.0442 - val_loss: 137.6704 - val_mean_absolute_error: 9.4495\n",
      "Epoch 12/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 224.7201 - mean_absolute_error: 11.9757 - val_loss: 139.1055 - val_mean_absolute_error: 9.4820\n",
      "Epoch 13/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 223.1121 - mean_absolute_error: 11.9388 - val_loss: 136.5930 - val_mean_absolute_error: 9.4222\n",
      "Epoch 14/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 221.4743 - mean_absolute_error: 11.9072 - val_loss: 139.5688 - val_mean_absolute_error: 9.4910\n",
      "Epoch 15/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 219.9188 - mean_absolute_error: 11.8564 - val_loss: 138.9692 - val_mean_absolute_error: 9.4780\n",
      "Epoch 16/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 218.2365 - mean_absolute_error: 11.8161 - val_loss: 139.7616 - val_mean_absolute_error: 9.5031\n",
      "Epoch 17/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 215.8917 - mean_absolute_error: 11.7483 - val_loss: 137.6200 - val_mean_absolute_error: 9.4452\n",
      "Epoch 18/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 214.8819 - mean_absolute_error: 11.7237 - val_loss: 138.7737 - val_mean_absolute_error: 9.4755\n",
      "Epoch 19/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 213.0940 - mean_absolute_error: 11.6683 - val_loss: 136.5052 - val_mean_absolute_error: 9.4182\n",
      "Epoch 20/20\n",
      "288096/288096 [==============================] - 2s 6us/step - loss: 211.5738 - mean_absolute_error: 11.6358 - val_loss: 136.9878 - val_mean_absolute_error: 9.4318\n"
     ]
    }
   ],
   "source": [
    "  # regression, for age before binning \n",
    "    \n",
    "model1 = keras.Sequential([\n",
    "    keras.layers.Dense(16,activation = tf.nn.relu, input_shape = (train_dataset.shape[1],) ),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(16,activation = tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1)   \n",
    "  ])\n",
    "  \n",
    "  \n",
    "model1.compile(loss= 'mse',  # mean square error\n",
    "               optimizer = tf.train.RMSPropOptimizer(0.001),\n",
    "               metrics=['mae'])\n",
    "# automatically stop epochs when val_loss stops decreasing\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience =20)\n",
    "history1 = model1.fit(train_dataset,train_labels, epochs = 20, batch_size = 1000,validation_split = 0.2, verbose=1, \n",
    "                              callbacks = [early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288096 samples, validate on 72024 samples\n",
      "Epoch 1/20\n",
      "288096/288096 [==============================] - 7s 26us/step - loss: 260.0547 - mean_absolute_error: 12.4481 - val_loss: 131.2446 - val_mean_absolute_error: 9.3852\n",
      "Epoch 2/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 155.5613 - mean_absolute_error: 10.0838 - val_loss: 131.6155 - val_mean_absolute_error: 9.4267\n",
      "Epoch 3/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 154.2383 - mean_absolute_error: 10.0376 - val_loss: 130.2846 - val_mean_absolute_error: 9.3126\n",
      "Epoch 4/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 153.6348 - mean_absolute_error: 10.0240 - val_loss: 131.1558 - val_mean_absolute_error: 9.4060\n",
      "Epoch 5/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 152.8754 - mean_absolute_error: 9.9940 - val_loss: 130.7067 - val_mean_absolute_error: 9.2761\n",
      "Epoch 6/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 152.3988 - mean_absolute_error: 9.9769 - val_loss: 130.2221 - val_mean_absolute_error: 9.3477\n",
      "Epoch 7/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 151.5663 - mean_absolute_error: 9.9506 - val_loss: 133.7610 - val_mean_absolute_error: 9.3098\n",
      "Epoch 8/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 151.3531 - mean_absolute_error: 9.9491 - val_loss: 129.9954 - val_mean_absolute_error: 9.2706\n",
      "Epoch 9/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 150.9381 - mean_absolute_error: 9.9329 - val_loss: 130.1598 - val_mean_absolute_error: 9.2681\n",
      "Epoch 10/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 150.0263 - mean_absolute_error: 9.9050 - val_loss: 130.6461 - val_mean_absolute_error: 9.2665\n",
      "Epoch 11/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 149.8369 - mean_absolute_error: 9.8968 - val_loss: 130.3523 - val_mean_absolute_error: 9.2705\n",
      "Epoch 12/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 149.7794 - mean_absolute_error: 9.9027 - val_loss: 130.3689 - val_mean_absolute_error: 9.2623\n",
      "Epoch 13/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 149.3228 - mean_absolute_error: 9.8881 - val_loss: 130.0391 - val_mean_absolute_error: 9.3408\n",
      "Epoch 14/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 148.5906 - mean_absolute_error: 9.8623 - val_loss: 129.6800 - val_mean_absolute_error: 9.2738\n",
      "Epoch 15/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 148.3374 - mean_absolute_error: 9.8518 - val_loss: 134.1482 - val_mean_absolute_error: 9.3089\n",
      "Epoch 16/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 147.6621 - mean_absolute_error: 9.8285 - val_loss: 129.5834 - val_mean_absolute_error: 9.2760\n",
      "Epoch 17/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 147.6703 - mean_absolute_error: 9.8400 - val_loss: 129.6479 - val_mean_absolute_error: 9.3082\n",
      "Epoch 18/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 147.0287 - mean_absolute_error: 9.8208 - val_loss: 129.6053 - val_mean_absolute_error: 9.3015\n",
      "Epoch 19/20\n",
      "288096/288096 [==============================] - 7s 23us/step - loss: 146.7147 - mean_absolute_error: 9.8053 - val_loss: 130.8477 - val_mean_absolute_error: 9.2699\n",
      "Epoch 20/20\n",
      "288096/288096 [==============================] - 7s 24us/step - loss: 146.3388 - mean_absolute_error: 9.7924 - val_loss: 133.8848 - val_mean_absolute_error: 9.3098\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(256,activation = tf.nn.relu, input_shape = (train_dataset.shape[1],) ),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128,activation = tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1)   \n",
    "  ])\n",
    "  \n",
    "  \n",
    "model2.compile(loss= 'mse',  # mean square error\n",
    "               optimizer = tf.train.RMSPropOptimizer(0.001),\n",
    "               metrics=['mae'])\n",
    "# automatically stop epochs when val_loss stops decreasing\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience =20)\n",
    "histor2 = model2.fit(train_dataset,train_labels, epochs = 20, batch_size = 1000,validation_split = 0.2, verbose=1, \n",
    "                              callbacks = [early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e589c573f7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model 1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model 2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'comparison of different models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history2' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_history(histories, key='mean_absolute_error'):\n",
    "  plot.figure(figsize=(16,10))\n",
    "  for name, history in histories:\n",
    "    val = plot.plot(history.epoch, history.history['val_'+key],\n",
    "                   '--', label=name.title()+' Validation')\n",
    "    plot.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "             label=name.title()+' Train')\n",
    "\n",
    "  plot.xlabel('Epochs')\n",
    "  plot.ylabel(key.replace('_',' ').title())\n",
    "  plot.legend()\n",
    "  plot.xlim([0,max(history.epoch)])\n",
    "  \n",
    "  \n",
    "plot_history([('model 1',history1),('model 2',history2)])\n",
    "plot.title('comparison of different models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model2.predict(test_dataset)\n",
    "plot.scatter(test_labels, test_predictions)\n",
    "plot.plot(range(10,60), range(10,60), 'r')\n",
    "plot.xlabel('testset - actual age')\n",
    "plot.ylabel('testset - predicted age')\n",
    "plot.title('actual vs prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## data with age binned ##############\n",
    "# put age into different bins, 5 years per bin, from 5 to 70, total 13 bins \n",
    "# [5-10) => 0\n",
    "# [10-15) => 1\n",
    "# [65-70) => 12\n",
    "data['userAgeBins'] = ((1+data.userAge)/5 ).apply(math.ceil)-2\n",
    "\n",
    "data.drop('userAge',axis =1)\n",
    "train_dataset_bin = data.sample(frac=0.8,random_state=0).astype('float64')   #############\n",
    "test_dataset_bin = data.drop(train_dataset_bin.index).astype('float64')\n",
    "\n",
    "train_labels_bin = train_dataset_bin['userAgeBins']\n",
    "train_dataset_bin = train_dataset_bin.drop('userAgeBins',axis = 1)\n",
    "test_labels_bin = test_dataset_bin['userAgeBins']\n",
    "test_dataset_bin = test_dataset_bin.drop('userAgeBins',axis = 1)\n",
    "\n",
    "#covnert dataframe to ndarrays for tensorflow input \n",
    "train_dataset_bin = train_dataset_bin.values\n",
    "train_labels_bin = train_labels_bin.values\n",
    "test_dataset_bin = test_dataset_bin.values\n",
    "test_labels_bin = test_labels_bin.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.figure()\n",
    "plot.hist(data.userAgeBins, bins = range(0,13))\n",
    "plot.figure()\n",
    "plot.hist(data.userAge.astype('int'), bins = range(5,75,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bin = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape = (train_dataset_bin.shape[1],)),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(13, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_bin.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss= 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_bin = model_bin.fit(train_dataset_bin,train_labels_bin, epochs =30, batch_size = 1000 ,validation_split=0.1, verbose=0)\n",
    "results = model_bin.evaluate(test_dataset_bin, test_labels_bin)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.figure(figsize = (20,10))\n",
    "plot.xlabel('Epoch')\n",
    "plot.ylabel('accuracy')\n",
    "plot.plot(history_bin.epoch, history_bin.history['acc'],'g',label='Train accuracy')\n",
    "plot.plot(history_bin.epoch, history_bin.history['val_acc'], 'g--',label='Val accuracy')\n",
    "plot.legend()\n",
    "plot.title('accuracy for the model with user age binned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_bin = model_bin.predict(test_dataset_bin)\n",
    "test_predictions_bin = pd.DataFrame(test_predictions_bin).apply(np.argmax, axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.subplot(2,1,1)\n",
    "plot.hist(test_predictions_bin)\n",
    "plot.title('predcition')\n",
    "\n",
    "plot.subplot(2,1,2)\n",
    "plot.hist(test_labels_bin)\n",
    "plot.title('test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without jitter, lots of overlap \n",
    "plot.figure()\n",
    "plot.scatter(test_labels_bin, test_predictions_bin)\n",
    "plot.plot(range(0,13), range(0,13), 'r')\n",
    "plot.xlabel('testset - actual age (bin)')\n",
    "plot.ylabel('testset - predicted age (bin)')\n",
    "plot.title('actual vs prediction (bin, without jitter)')\n",
    "plot.xticks(np.arange(0,13,1))\n",
    "plot.yticks(np.arange(0,13,1))\n",
    "\n",
    "\n",
    "# manually add jitter \n",
    "plot.figure()\n",
    "test_labels_bin_jitter = test_labels_bin + np.random.rand(test_labels_bin.shape[0])\n",
    "test_predictions_bin_jitter = test_predictions_bin + np.random.rand(test_predictions_bin.shape[0])\n",
    "plot.scatter(test_labels_bin_jitter, test_predictions_bin_jitter)\n",
    "plot.plot(range(0,13), range(0,13), 'r')\n",
    "plot.xlabel('testset - actual age (bin)')\n",
    "plot.ylabel('testset - predicted age (bin)')\n",
    "plot.title('actual vs prediction (bin, with jitter)')\n",
    "plot.xticks(np.arange(0,13,1))\n",
    "plot.yticks(np.arange(0,13,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(test_labels_bin.shape[0])*0.1\n",
    "# test_labels_bin\n",
    "plot.scatter(test_labels_bin + np.random.rand(test_labels_bin.shape[0])*1, test_predictions_bin+np.random.rand(test_labels_bin.shape[0])*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_dataset has the shape:',train_dataset.shape)\n",
    "print('train_labels has the shape:',train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}