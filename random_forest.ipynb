{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources\n",
    "from __future__ import print_function\n",
    "!pip install tensorflow==1.12\n",
    "import google.datalab.bigquery as bq\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import math\n",
    "from pandas.io import gbq\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: 30c12983-b150-4f0b-ad09-f9f6eb7a3894\n",
      "Query running...\n",
      "Query done.\n",
      "Cache hit.\n",
      "\n",
      "Retrieving results...\n",
      "Got 100000 rows.\n",
      "\n",
      "Total time taken 18.43 s.\n",
      "Finished at 2019-01-16 05:44:50.\n",
      "(56075, 8)\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM `sparkline-integrators.tencent_lookalike.export_to_datalab_gender_only` ORDER BY fullVisitorId  LIMIT 100000 \" \n",
    "data_original = gbq.read_gbq(query,project_id = \"sparkline-integrators\" )\n",
    "data= data_original\n",
    "\n",
    "# remove rows with null values\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "# remove unused columns\n",
    "data = data.drop(['visitId','VisitingHour','VisitingDayOfWeek'],axis=1)\n",
    "\n",
    "# prepare column browser, change browers that are not specified below to 'other'\n",
    "data.loc[(data.browser != 'Chrome') &\n",
    "         (data.browser != 'Safari') &\n",
    "         (data.browser != 'Firefox') &\n",
    "         (data.browser !='Internet Explorer'),'browser'] = 'other'\n",
    "# prepare column language\n",
    "data.rename(columns = {'LANGUAGE':'language'}, inplace=True)\n",
    "data.loc[data.language.str.contains('en'),'language'] = 'en'  #data has inconsistent values e.g. 'en','en-en','en-bg'\n",
    "data.loc[data.language.str.contains('th'),'language'] = 'th'\n",
    "data.language.str.contains('en|th')\n",
    "data.loc[(data.language!='th') & \n",
    "         (data.language!='en'),'language'] = 'other'\n",
    "\n",
    "# prepare column operatingSystem\n",
    "data.loc[(data.operatingSystem != 'Windows') &\n",
    "         (data.operatingSystem != 'Android') &\n",
    "         (data.operatingSystem != 'Macintosh') &\n",
    "         (data.operatingSystem !='iOS'),'operatingSystem'] = 'other'\n",
    "\n",
    "# prepare column source \n",
    "data.loc[data.source.str.contains('facebook'),'source'] = 'facebook' #data has inconsistent value such as 'facebook','facebook.com'\n",
    "data.loc[data.source.str.contains('google'),'source'] = 'google'\n",
    "data.loc[data.source.str.contains('sanook'),'source'] = 'sanook'\n",
    "data.loc[data.source.str.contains('direct'),'source'] = 'direct'\n",
    "data.loc[(data.source != 'facebook') &\n",
    "         (data.source != 'google') &\n",
    "         (data.source != 'sanook') &\n",
    "         (data.source !='direct'),'source'] = 'other'\n",
    "\n",
    "# remove rows where contentCategory contains non-english characters\n",
    "data = data[data.contentCategory.str.contains('^[A-Za-z]+$', regex=True)]\n",
    "data.loc[:,'contentCategory'] = data.contentCategory.str.lower()\n",
    "data.loc[:,'userGender'] = data.userGender.str.lower()\n",
    "# female=0, male=1\n",
    "data.userGender.replace({\n",
    "  'female':'0',\n",
    "  'male':'1'\n",
    "}, inplace=True)  \n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "def make_pivot_table(columns, _id):\n",
    "    result =None\n",
    "    for column in columns:\n",
    "        pivot = data.loc[:,[_id,column]]\n",
    "        pivot = pivot.pivot_table(index=id,columns=column,aggfunc= any)\n",
    "        pivot.columns = ['_'.join((column,i)) for i  in pivot.columns]\n",
    "        if result is None:\n",
    "          result = pivot\n",
    "        else:\n",
    "          result = result.join(pivot)\n",
    "        \n",
    "    result = result.replace({\n",
    "      True:1,\n",
    "      None:0\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "gender = data.loc[:,['fullVisitorId','userGender']].drop_duplicates().set_index('fullVisitorId')    \n",
    "data = make_pivot_table(data.columns[1:-1],'fullVisitorId')\n",
    "data = data.join(gender)\n",
    "\n",
    "#remove columns with less than 0.1% of 1s  \n",
    "data = data[data.columns[data.sum()>data.shape[0]*0.001]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, train_labels, test_labels = train_test_split(data.drop('userGender',axis=1), data['userGender'], test_size = 0.2, random_state = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (12033, 75)\n",
      "Training Labels Shape: (12033,)\n",
      "Testing Features Shape: (3009, 75)\n",
      "Testing Labels Shape: (3009,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_dataset.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_dataset.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   20.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy rate = 0.5596543702226653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, verbose = 1)\n",
    "rf.fit(train_dataset, train_labels)\n",
    "predictions = rf.predict(test_dataset)\n",
    "accuracy= (predictions == test_labels).sum()/test_labels.shape[0]\n",
    "print(\"accuracy rate = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
